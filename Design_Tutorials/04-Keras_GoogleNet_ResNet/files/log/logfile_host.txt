 Copyright 2021 Xilinx Inc.
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
     http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.




############################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for LeNet on CIFAR10
############################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.

Model: "LeNet"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1_input (InputLayer)  [(None, 32, 32, 3)]       0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 50)        3800
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 50)        200
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 50)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 50)        0
_________________________________________________________________
flatten (Flatten)            (None, 12800)             0
_________________________________________________________________
dense (Dense)                (None, 500)               6400500
_________________________________________________________________
activation_2 (Activation)    (None, 500)               0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                5010
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0
=================================================================
Total params: 6,409,510
Trainable params: 6,409,410
Non-trainable params: 100
_________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_3/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


#################################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for miniVggNet  on CIFAR10
#################################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.

Model: "miniVggNet"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1_input (InputLayer)  [(None, 32, 32, 3)]       0
_________________________________________________________________
conv2d (Conv2D)              (None, 32, 32, 32)        864
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 32)        128
_________________________________________________________________
activation (Activation)      (None, 32, 32, 32)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 32)        9216
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 64)        18432
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
activation_2 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        36864
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0
_________________________________________________________________
flatten (Flatten)            (None, 4096)              0
_________________________________________________________________
dense (Dense)                (None, 512)               2097664
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048
_________________________________________________________________
activation_4 (Activation)    (None, 512)               0
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                5130
_________________________________________________________________
activation_5 (Activation)    (None, 10)                0
=================================================================
Total params: 2,170,986
Trainable params: 2,169,578
Non-trainable params: 1,408
_________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_5/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


#################################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for miniGoogleNet  on CIFAR10
#################################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: "miniGoogleNet"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
conv2d_1_input (InputLayer)     [(None, 32, 32, 3)]  0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 32, 32, 96)   2688        conv2d_1_input[0][0]
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 32, 32, 96)   384         conv2d[0][0]
__________________________________________________________________________________________________
activation (Activation)         (None, 32, 32, 96)   0           batch_normalization[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 32)   3104        activation[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 32)   27680       activation[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 32, 32, 64)   0           activation_1[0][0]
                                                                 activation_2[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 32)   2080        concatenate[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 48)   27696       concatenate[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         conv2d_4[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           activation_3[0][0]
                                                                 activation_4[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 15, 15, 80)   57680       concatenate_1[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 15, 15, 80)   320         conv2d_5[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 15, 15, 80)   0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 15, 15, 80)   0           concatenate_1[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 15, 15, 160)  0           activation_5[0][0]
                                                                 max_pooling2d[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 15, 15, 112)  18032       concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 15, 15, 48)   69168       concatenate_2[0][0]
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 15, 15, 112)  448         conv2d_6[0][0]
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 15, 15, 48)   192         conv2d_7[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 15, 15, 112)  0           batch_normalization_6[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 15, 15, 48)   0           batch_normalization_7[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 15, 15, 160)  0           activation_6[0][0]
                                                                 activation_7[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 15, 15, 96)   15456       concatenate_3[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 15, 15, 64)   92224       concatenate_3[0][0]
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 15, 15, 96)   384         conv2d_8[0][0]
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 15, 15, 64)   256         conv2d_9[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 15, 15, 96)   0           batch_normalization_8[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 15, 15, 160)  0           activation_8[0][0]
                                                                 activation_9[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 15, 15, 80)   12880       concatenate_4[0][0]              WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.


__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 15, 15, 80)   115280      concatenate_4[0][0]
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 15, 15, 80)   320         conv2d_10[0][0]
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 15, 15, 80)   320         conv2d_11[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 15, 15, 80)   0           batch_normalization_10[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 15, 15, 80)   0           batch_normalization_11[0][0]
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 15, 15, 160)  0           activation_10[0][0]
                                                                 activation_11[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 15, 15, 48)   7728        concatenate_5[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 15, 15, 96)   138336      concatenate_5[0][0]
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 15, 15, 48)   192         conv2d_12[0][0]
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 15, 15, 96)   384         conv2d_13[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 15, 15, 48)   0           batch_normalization_12[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 15, 15, 96)   0           batch_normalization_13[0][0]
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 15, 15, 144)  0           activation_12[0][0]
                                                                 activation_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 7, 7, 96)     124512      concatenate_6[0][0]
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 7, 7, 96)     384         conv2d_14[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 7, 7, 96)     0           batch_normalization_14[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 144)    0           concatenate_6[0][0]
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 7, 7, 240)    0           activation_14[0][0]
                                                                 max_pooling2d_1[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 7, 7, 176)    42416       concatenate_7[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 7, 7, 160)    345760      concatenate_7[0][0]
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 7, 7, 176)    704         conv2d_15[0][0]
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 7, 7, 160)    640         conv2d_16[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 7, 7, 176)    0           batch_normalization_15[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 7, 7, 160)    0           batch_normalization_16[0][0]
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 7, 7, 336)    0           activation_15[0][0]
                                                                 activation_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 7, 7, 176)    59312       concatenate_8[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 7, 7, 160)    484000      concatenate_8[0][0]
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 7, 7, 176)    704         conv2d_17[0][0]
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 7, 7, 160)    640         conv2d_18[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 7, 7, 176)    0           batch_normalization_17[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 7, 7, 160)    0           batch_normalization_18[0][0]
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 7, 7, 336)    0           activation_17[0][0]
                                                                 activation_18[0][0]
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 1, 1, 336)    0           concatenate_9[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1, 1, 336)    0           average_pooling2d[0][0]
__________________________________________________________________________________________________
flatten (Flatten)               (None, 336)          0           dropout[0][0]
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           3370        flatten[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 10)           0           dense[0][0]
==================================================================================================
Total params: 1,656,250
Trainable params: 1,652,826
Non-trainable params: 3,424
__________________________________________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_19/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


#################################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for miniResNet  on CIFAR10
#################################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: "resnet"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
conv2d_1_input (InputLayer)     [(None, 32, 32, 3)]  0
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 32, 32, 3)    12          conv2d_1_input[0][0]
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 32, 32, 64)   1728        batch_normalization[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d[0][0]
__________________________________________________________________________________________________
activation (Activation)         (None, 32, 32, 64)   0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   1024        activation[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2304        activation_1[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 64)   1024        activation_2[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 64)   4096        activation[0][0]
__________________________________________________________________________________________________
add (Add)                       (None, 32, 32, 64)   0           conv2d_3[0][0]
                                                                 conv2d_4[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   1024        activation_3[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2304        activation_4[0][0]
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 64)   1024        activation_5[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]
                                                                 add[0][0]
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   1024        activation_6[0][0]
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2304        activation_7[0][0]
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 64)   1024        activation_8[0][0]
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_10[0][0]
                                                                 add_1[0][0]
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_2[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   1024        activation_9[0][0]
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_11[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 16)   2304        activation_10[0][0]
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 64)   1024        activation_11[0][0]
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 64)   0           conv2d_13[0][0]
                                                                 add_2[0][0]
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 16)   1024        activation_12[0][0]
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 16)   2304        activation_13[0][0]
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 64)   1024        activation_14[0][0]
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 64)   0           conv2d_16[0][0]
                                                                 add_3[0][0]
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         add_4[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 64)   0           batch_normalization_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 16)   1024        activation_15[0][0]
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 16)   2304        activation_16[0][0]
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 64)   1024        activation_17[0][0]
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 64)   0           conv2d_19[0][0]
                                                                 add_4[0][0]
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         add_5[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 64)   0           batch_normalization_19[0][0]
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 32, 32, 16)   1024        activation_18[0][0]
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 32, 32, 16)   2304        activation_19[0][0]
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 32, 32, 64)   1024        activation_20[0][0]
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 64)   0           conv2d_22[0][0]
                                                                 add_5[0][0]
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         add_6[0][0]
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_22[0][0]
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 32, 32, 16)   1024        activation_21[0][0]
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 32, 32, 16)   2304        activation_22[0][0]
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_24[0][0]
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 32, 32, 64)   1024        activation_23[0][0]
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 64)   0           conv2d_25[0][0]
                                                                 add_6[0][0]
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         add_7[0][0]
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_25[0][0]
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 32, 32, 16)   1024        activation_24[0][0]
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_26[0][0]
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 32, 32, 16)   2304        activation_25[0][0]
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 32, 32, 16)   0           batch_normalization_27[0][0]
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 32, 32, 64)   1024        activation_26[0][0]
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 64)   0           conv2d_28[0][0]
                                                                 add_7[0][0]
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 32, 32, 64)   256         add_8[0][0]
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_28[0][0]
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 32, 32, 32)   2048        activation_27[0][0]
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 32, 32, 32)   128         conv2d_29[0][0]
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 32, 32, 32)   0           batch_normalization_29[0][0]
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 32)   9216        activation_28[0][0]
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 128)  4096        activation_29[0][0]
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 16, 16, 128)  8192        activation_27[0][0]
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 128)  0           conv2d_31[0][0]
                                                                 conv2d_32[0][0]
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_9[0][0]
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 128)  0           batch_normalization_31[0][0]
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 16, 16, 32)   4096        activation_30[0][0]
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 16, 16, 32)   9216        activation_31[0][0]
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_33[0][0]
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 128)  4096        activation_32[0][0]
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 128)  0           conv2d_35[0][0]
                                                                 add_9[0][0]
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 128)  0           batch_normalization_34[0][0]
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 16, 16, 32)   4096        activation_33[0][0]
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_35[0][0]
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 16, 16, 32)   9216        activation_34[0][0]
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 16, 16, 128)  4096        activation_35[0][0]
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 128)  0           conv2d_38[0][0]
                                                                 add_10[0][0]
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 128)  0           batch_normalization_37[0][0]
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 16, 16, 32)   4096        activation_36[0][0]
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         conv2d_39[0][0]
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 16, 16, 32)   9216        activation_37[0][0]
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         conv2d_40[0][0]
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_39[0][0]
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 16, 16, 128)  4096        activation_38[0][0]
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 128)  0           conv2d_41[0][0]
                                                                 add_11[0][0]
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_40[0][0]
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 16, 16, 32)   4096        activation_39[0][0]
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         conv2d_42[0][0]
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_41[0][0]
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 16, 16, 32)   9216        activation_40[0][0]
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 16, 16, 32)   128         conv2d_43[0][0]
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 16, 16, 32)   0           batch_normalization_42[0][0]
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 16, 16, 128)  4096        activation_41[0][0]
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_44[0][0]
                                                                 add_12[0][0]
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_43[0][0]
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 16, 16, 32)   4096        activation_42[0][0]
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 16, 16, 32)   128         conv2d_45[0][0]
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 16, 16, 32)   0           batch_normalization_44[0][0]
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 16, 16, 32)   9216        activation_43[0][0]
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_46[0][0]
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 16, 16, 128)  4096        activation_44[0][0]
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 128)  0           conv2d_47[0][0]
                                                                 add_13[0][0]
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_46[0][0]
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 16, 16, 32)   4096        activation_45[0][0]
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_48[0][0]
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 16, 16, 32)   9216        activation_46[0][0]
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_49[0][0]
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 16, 16, 128)  4096        activation_47[0][0]
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 128)  0           conv2d_50[0][0]
                                                                 add_14[0][0]
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_49[0][0]
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 16, 16, 32)   4096        activation_48[0][0]
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_51[0][0]
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 16, 16, 32)   9216        activation_49[0][0]
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv2d_52[0][0]
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_51[0][0]
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 16, 16, 128)  4096        activation_50[0][0]
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 128)  0           conv2d_53[0][0]
                                                                 add_15[0][0]
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 16, 16, 128)  512         add_16[0][0]
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_52[0][0]
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 16, 16, 32)   4096        activation_51[0][0]
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 16, 16, 32)   0           batch_normalization_53[0][0]
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 16, 16, 32)   9216        activation_52[0][0]
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 16, 16, 32)   0           batch_normalization_54[0][0]
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 16, 16, 128)  4096        activation_53[0][0]
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 128)  0           conv2d_56[0][0]
                                                                 add_16[0][0]
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 16, 16, 128)  512         add_17[0][0]
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_55[0][0]
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 16, 16, 64)   8192        activation_54[0][0]
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         conv2d_57[0][0]
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 8, 8, 64)     36864       activation_55[0][0]
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_57[0][0]
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 8, 8, 256)    16384       activation_56[0][0]
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 8, 8, 256)    32768       activation_54[0][0]
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 8, 256)    0           conv2d_59[0][0]
                                                                 conv2d_60[0][0]
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 8, 8, 256)    0           batch_normalization_58[0][0]
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 8, 8, 64)     16384       activation_57[0][0]
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_59[0][0]
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 8, 8, 64)     36864       activation_58[0][0]
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 8, 8, 256)    16384       activation_59[0][0]
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 8, 256)    0           conv2d_63[0][0]
                                                                 add_18[0][0]
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        add_19[0][0]
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 8, 8, 64)     16384       activation_60[0][0]
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 8, 8, 64)     256         conv2d_64[0][0]
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 8, 8, 64)     0           batch_normalization_62[0][0]
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 8, 8, 64)     36864       activation_61[0][0]
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 8, 8, 64)     256         conv2d_65[0][0]
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 8, 8, 64)     0           batch_normalization_63[0][0]
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 8, 8, 256)    16384       activation_62[0][0]
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 8, 256)    0           conv2d_66[0][0]
                                                                 add_19[0][0]
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        add_20[0][0]
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 8, 8, 64)     16384       activation_63[0][0]
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 8, 8, 64)     256         conv2d_67[0][0]
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 8, 8, 64)     0           batch_normalization_65[0][0]
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 8, 8, 64)     36864       activation_64[0][0]
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 8, 8, 64)     256         conv2d_68[0][0]
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 8, 8, 64)     0           batch_normalization_66[0][0]
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 8, 8, 256)    16384       activation_65[0][0]
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 256)    0           conv2d_69[0][0]
                                                                 add_20[0][0]
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        add_21[0][0]
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 8, 8, 64)     16384       activation_66[0][0]
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 8, 8, 64)     256         conv2d_70[0][0]
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 8, 8, 64)     0           batch_normalization_68[0][0]
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 8, 8, 64)     36864       activation_67[0][0]
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 8, 8, 64)     256         conv2d_71[0][0]
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 8, 8, 64)     0           batch_normalization_69[0][0]
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 8, 8, 256)    16384       activation_68[0][0]
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 256)    0           conv2d_72[0][0]
                                                                 add_21[0][0]
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        add_22[0][0]
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 8, 8, 64)     16384       activation_69[0][0]
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 8, 8, 64)     256         conv2d_73[0][0]
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 8, 8, 64)     0           batch_normalization_71[0][0]
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 8, 8, 64)     36864       activation_70[0][0]
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 8, 8, 64)     256         conv2d_74[0][0]
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 8, 8, 64)     0           batch_normalization_72[0][0]
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 8, 8, 256)    16384       activation_71[0][0]
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 256)    0           conv2d_75[0][0]
                                                                 add_22[0][0]
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        add_23[0][0]
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 8, 8, 64)     16384       activation_72[0][0]
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 8, 8, 64)     256         conv2d_76[0][0]
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 8, 8, 64)     0           batch_normalization_74[0][0]
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 8, 8, 64)     36864       activation_73[0][0]
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 8, 8, 64)     256         conv2d_77[0][0]
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 8, 8, 64)     0           batch_normalization_75[0][0]
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 8, 8, 256)    16384       activation_74[0][0]
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 256)    0           conv2d_78[0][0]
                                                                 add_23[0][0]
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 8, 8, 256)    1024        add_24[0][0]
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 8, 8, 256)    0           batch_normalization_76[0][0]
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 8, 8, 64)     16384       activation_75[0][0]
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 8, 8, 64)     256         conv2d_79[0][0]
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 8, 8, 64)     0           batch_normalization_77[0][0]
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 8, 8, 64)     36864       activation_76[0][0]
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 8, 8, 64)     256         conv2d_80[0][0]
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 8, 8, 64)     0           batch_normalization_78[0][0]
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 8, 8, 256)    16384       activation_77[0][0]
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 256)    0           conv2d_81[0][0]
                                                                 add_24[0][0]
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 8, 8, 256)    1024        add_25[0][0]
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 8, 8, 256)    0           batch_normalization_79[0][0]
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 8, 8, 64)     16384       activation_78[0][0]
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 8, 8, 64)     256         conv2d_82[0][0]
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 8, 8, 64)     0           batch_normalization_80[0][0]
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 8, 8, 64)     36864       activation_79[0][0]
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 8, 8, 64)     256         conv2d_83[0][0]
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 8, 8, 64)     0           batch_normalization_81[0][0]
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 8, 8, 256)    16384       activation_80[0][0]
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 256)    0           conv2d_84[0][0]
                                                                 add_25[0][0]                     WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.


__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 8, 8, 256)    1024        add_26[0][0]
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 8, 8, 256)    0           batch_normalization_82[0][0]
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_81[0][0]
__________________________________________________________________________________________________
flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           2570        flatten[0][0]
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 10)           0           dense[0][0]
==================================================================================================
Total params: 886,102
Trainable params: 873,872
Non-trainable params: 12,230
__________________________________________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_82/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


##########################################################################
FREEZE GRAPH of LeNet on CIFAR10
##########################################################################
rm: cannot remove './build/freeze/cifar10/Lenet/*': No such file or directory
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:28:04.805878 140025658668864 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:28:04.810335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:28:04.872890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:04.873084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:04.874078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:04.875030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:04.875282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:04.876475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:04.877441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:04.880355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:04.881714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:04.882025: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:28:04.902960: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:28:04.905309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564a216a0970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:04.905321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:28:04.979983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564a20452660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:04.980027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:28:04.982445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:04.982525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:04.982547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:04.982566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:04.982585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:04.982604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:04.982623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:04.982642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:04.986728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:04.986815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:04.990138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:28:04.990161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:28:04.990171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:28:04.994447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/cifar10/LeNet/float_model.ckpt
I1004 07:28:05.078514 140025658668864 saver.py:1284] Restoring parameters from ./build/tf_chkpts/cifar10/LeNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:28:06.019257 140025658668864 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:28:06.019681 140025658668864 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 10 variables.
I1004 07:28:06.097208 140025658668864 graph_util_impl.py:334] Froze 10 variables.
INFO:tensorflow:Converted 10 variables to const ops.
I1004 07:28:06.134648 140025658668864 graph_util_impl.py:394] Converted 10 variables to const ops.
Loaded meta graph file './build/tf_chkpts/cifar10/LeNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of LeNet  on CIFAR10
##########################################################################
Op types used: 14 Const, 10 Identity, 3 BiasAdd, 2 MatMul, 2 Relu, 1 Conv2D, 1 FusedBatchNormV3, 1 MaxPool, 1 Pack, 1 Placeholder, 1 Reshape, 1 Shape, 1 Softmax, 1 StridedSlice

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_3/Softmax, op=Softmax)

##########################################################################
FREEZE GRAPH of miniVggNet  on CIFAR10
##########################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:28:11.015368 140518304393024 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:28:11.018641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:28:11.080969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:11.081164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:11.082355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:11.083517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:11.083821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:11.085317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:11.086523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:11.089958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:11.091752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:11.092116: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:28:11.115493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:28:11.117802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ccf7683710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:11.117832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:28:11.192452: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ccf60e2440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:11.192494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:28:11.195089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:11.195171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:11.195194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:11.195214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:11.195233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:11.195252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:11.195271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:11.195291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:11.199533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:11.199614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:11.202895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:28:11.202917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:28:11.202926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:28:11.208351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/cifar10/miniVggNet/float_model.ckpt
I1004 07:28:11.382656 140518304393024 saver.py:1284] Restoring parameters from ./build/tf_chkpts/cifar10/miniVggNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:28:12.324518 140518304393024 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:28:12.324697 140518304393024 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 28 variables.
I1004 07:28:12.361841 140518304393024 graph_util_impl.py:334] Froze 28 variables.
INFO:tensorflow:Converted 28 variables to const ops.
I1004 07:28:12.384964 140518304393024 graph_util_impl.py:394] Converted 28 variables to const ops.
Loaded meta graph file './build/tf_chkpts/cifar10/miniVggNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of miniVggNet on CIFAR10
##########################################################################
Op types used: 33 Const, 31 Identity, 5 Relu, 4 Conv2D, 4 FusedBatchNormV3, 3 Mul, 2 BiasAdd, 2 MatMul, 2 MaxPool, 2 AddV2, 1 Sub, 1 StridedSlice, 1 Softmax, 1 Shape, 1 Rsqrt, 1 Reshape, 1 Placeholder, 1 Pack

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_5/Softmax, op=Softmax)
##########################################################################
FREEZE GRAPH of miniGoogleNet  on CIFAR10
##########################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:28:16.273412 140455032858432 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:28:16.282812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:28:16.344356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:16.344558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:16.345427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:16.346407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:16.346694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:16.347911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:16.348870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:16.351885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:16.353259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:16.353575: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:28:16.375035: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:28:16.376982: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561463f92410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:16.377000: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:28:16.450486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561462d444f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:16.450529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:28:16.452936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:16.453017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:16.453039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:16.453059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:16.453078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:16.453098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:16.453117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:16.453137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:16.457213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:16.457275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:16.460563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:28:16.460587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:28:16.460597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:28:16.464557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/cifar10/miniGoogleNet/float_model.ckpt
I1004 07:28:16.833337 140455032858432 saver.py:1284] Restoring parameters from ./build/tf_chkpts/cifar10/miniGoogleNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:28:17.953409 140455032858432 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:28:17.953819 140455032858432 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 116 variables.
I1004 07:28:18.097324 140455032858432 graph_util_impl.py:334] Froze 116 variables.
INFO:tensorflow:Converted 116 variables to const ops.
I1004 07:28:18.112214 140455032858432 graph_util_impl.py:394] Converted 116 variables to const ops.
Loaded meta graph file './build/tf_chkpts/cifar10/miniGoogleNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of miniGoogleNet  on CIFAR10
##########################################################################
Op types used: 130 Const, 117 Identity, 20 BiasAdd, 19 Conv2D, 19 FusedBatchNormV3, 19 Relu, 10 ConcatV2, 2 MaxPool, 1 AvgPool, 1 MatMul, 1 Pack, 1 Placeholder, 1 Reshape, 1 Shape, 1 Softmax, 1 StridedSlice

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_19/Softmax, op=Softmax)
##########################################################################
FREEZE GRAPH of miniResNet  on CIFAR10
##########################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:28:22.062953 140133408171840 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:28:22.085647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:28:22.150304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:22.150528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:22.151665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:22.152643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:22.152916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:22.154194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:22.155214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:22.158070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:22.159531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:22.159877: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:28:22.181979: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:28:22.184058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c33eb3b4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:22.184089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:28:22.262737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c33d8ed410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:28:22.262788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:28:22.265286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:28:22.265370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:22.265393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:28:22.265412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:28:22.265431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:28:22.265451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:28:22.265470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:28:22.265490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:28:22.269811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:28:22.269878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:28:22.273038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:28:22.273058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:28:22.273067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:28:22.276710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/cifar10/miniResNet/float_model.ckpt
I1004 07:28:23.620651 140133408171840 saver.py:1284] Restoring parameters from ./build/tf_chkpts/cifar10/miniResNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:28:25.397387 140133408171840 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:28:25.397828 140133408171840 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 419 variables.
I1004 07:28:25.919109 140133408171840 graph_util_impl.py:334] Froze 419 variables.
INFO:tensorflow:Converted 419 variables to const ops.
I1004 07:28:25.956903 140133408171840 graph_util_impl.py:394] Converted 419 variables to const ops.
Loaded meta graph file './build/tf_chkpts/cifar10/miniResNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of miniResNet
##########################################################################
Op types used: 423 Const, 419 Identity, 85 Conv2D, 83 FusedBatchNormV3, 82 Relu, 27 AddV2, 1 AvgPool, 1 BiasAdd, 1 MatMul, 1 Pack, 1 Placeholder, 1 Reshape, 1 Shape, 1 Softmax, 1 StridedSlice

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_82/Softmax, op=Softmax)

##########################################################################
FREEZE GRAPH COMPLETED
##########################################################################


##########################################################################
EVALUATE FROZEN GRAPH of LeNet on CIFAR10
##########################################################################
2021-10-04 07:29:25.055437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:29:25.098751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:25.099046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:25.100379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:25.101491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:25.101800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:25.102909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:25.103754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:25.106565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:25.108605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:25.108904: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:29:25.131501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:29:25.133138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5626c687e8d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:25.133153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:29:25.213449: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5626c530a6c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:25.213493: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:29:25.215932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:25.216037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:25.216065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:25.216089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:25.216113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:25.216136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:25.216159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:25.216183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:25.220311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:25.220390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:25.224060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:29:25.224080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:29:25.224089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:29:25.227711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:29:26.277160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:26.702606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:28.238460: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.6792
 Top 5 accuracy with validation set: 0.9688
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH of miniVggNet  on CIFAR10
##########################################################################
2021-10-04 07:29:35.786966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:29:35.836358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:35.836558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:35.837409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:35.838310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:35.838602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:35.839592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:35.840327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:35.842569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:35.844018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:35.844318: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:29:35.865512: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:29:35.867463: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644998f1810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:35.867483: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:29:35.947722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644980404a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:35.947765: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:29:35.950401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:35.950494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:35.950521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:35.950545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:35.950569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:35.950592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:35.950615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:35.950639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:35.954918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:35.955005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:35.959014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:29:35.959038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:29:35.959048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:29:35.963269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:29:36.931913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:37.053887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:37.564591: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.8438
 Top 5 accuracy with validation set: 0.9900
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH of GoogleNet  on CIFAR10
##########################################################################
2021-10-04 07:29:45.690578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:29:45.752213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:45.752438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:45.753376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:45.754272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:45.754539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:45.755541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:45.756314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:45.758633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:45.760118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:45.760403: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:29:45.769038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:29:45.770511: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595cc81e9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:45.770541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:29:45.844275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595cc880fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:45.844318: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:29:45.846781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:45.846874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:45.846901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:45.846925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:45.846948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:45.846972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:45.846995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:45.847019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:45.851115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:45.851190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:45.855074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:29:45.855096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:29:45.855106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:29:45.859453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:29:46.896039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:47.033984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:47.548648: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.8828
 Top 5 accuracy with validation set: 0.9964
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH of ResNet  on CIFAR10
##########################################################################
2021-10-04 07:29:57.812175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:29:57.860047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:57.860264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:57.861455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:57.862410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:57.862655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:57.863620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:57.864347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:57.866640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:57.868016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:57.868347: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:29:57.888479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:29:57.891000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5560af9a7700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:57.891032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:29:57.967663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5560ae0fbf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:29:57.967706: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:29:57.970300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:29:57.970394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:57.970421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:57.970445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:29:57.970469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:29:57.970493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:29:57.970517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:29:57.970554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:57.974815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:29:57.974896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:29:57.978903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:29:57.978928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:29:57.978938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:29:57.982593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:29:59.172473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:29:59.291028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:29:59.828788: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.9358
 Top 5 accuracy with validation set: 0.9968
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH COMPLETED  on CIFAR10
##########################################################################


##########################################################################
QUANTIZE LeNet on CIFAR10
##########################################################################
2021-10-04 07:30:06.358424: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:00 ETA:   0:00:08
 10% (2 of 20) |##                       | Elapsed Time: 0:00:00 ETA:   0:00:08
 15% (3 of 20) |###                      | Elapsed Time: 0:00:01 ETA:   0:00:08
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:02 ETA:   0:00:08
 25% (5 of 20) |######                   | Elapsed Time: 0:00:02 ETA:   0:00:07
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:03 ETA:   0:00:07
 35% (7 of 20) |########                 | Elapsed Time: 0:00:03 ETA:   0:00:07
 40% (8 of 20) |##########               | Elapsed Time: 0:00:04 ETA:   0:00:06
 45% (9 of 20) |###########              | Elapsed Time: 0:00:04 ETA:   0:00:05
 50% (10 of 20) |############            | Elapsed Time: 0:00:05 ETA:   0:00:05
 55% (11 of 20) |#############           | Elapsed Time: 0:00:05 ETA:   0:00:04
 60% (12 of 20) |##############          | Elapsed Time: 0:00:06 ETA:   0:00:04
 65% (13 of 20) |###############         | Elapsed Time: 0:00:06 ETA:   0:00:03
 70% (14 of 20) |################        | Elapsed Time: 0:00:07 ETA:   0:00:03
 75% (15 of 20) |##################      | Elapsed Time: 0:00:07 ETA:   0:00:02
 80% (16 of 20) |###################     | Elapsed Time: 0:00:08 ETA:   0:00:02
 85% (17 of 20) |####################    | Elapsed Time: 0:00:08 ETA:   0:00:01
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:09 ETA:   0:00:01
 95% (19 of 20) |######################  | Elapsed Time: 0:00:10 ETA:   0:00:00
100% (20 of 20) |########################| Elapsed Time: 0:00:10 Time:  0:00:10
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/cifar10/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/cifar10/LeNet/quantize_eval_model.pb

##########################################################################
QUANTIZE miniVggNet  on CIFAR10
##########################################################################
2021-10-04 07:30:22.139794: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:00 ETA:   0:00:03
 10% (2 of 20) |##                       | Elapsed Time: 0:00:00 ETA:   0:00:03
 15% (3 of 20) |###                      | Elapsed Time: 0:00:00 ETA:   0:00:02
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:00 ETA:   0:00:02
 25% (5 of 20) |######                   | Elapsed Time: 0:00:00 ETA:   0:00:02
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:01 ETA:   0:00:02
 35% (7 of 20) |########                 | Elapsed Time: 0:00:01 ETA:   0:00:02
 40% (8 of 20) |##########               | Elapsed Time: 0:00:01 ETA:   0:00:02
 45% (9 of 20) |###########              | Elapsed Time: 0:00:01 ETA:   0:00:01
 50% (10 of 20) |############            | Elapsed Time: 0:00:01 ETA:   0:00:01
 55% (11 of 20) |#############           | Elapsed Time: 0:00:01 ETA:   0:00:01
 60% (12 of 20) |##############          | Elapsed Time: 0:00:02 ETA:   0:00:01
 65% (13 of 20) |###############         | Elapsed Time: 0:00:02 ETA:   0:00:01
 70% (14 of 20) |################        | Elapsed Time: 0:00:02 ETA:   0:00:01
 75% (15 of 20) |##################      | Elapsed Time: 0:00:02 ETA:   0:00:00
 80% (16 of 20) |###################     | Elapsed Time: 0:00:02 ETA:   0:00:00
 85% (17 of 20) |####################    | Elapsed Time: 0:00:02 ETA:   0:00:00
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:03 ETA:   0:00:00
 95% (19 of 20) |######################  | Elapsed Time: 0:00:03 ETA:   0:00:00
100% (20 of 20) |########################| Elapsed Time: 0:00:03 Time:  0:00:03
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/cifar10/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb

##########################################################################
QUANTIZE miniGoogleNet  on CIFAR10
##########################################################################
2021-10-04 07:30:30.202088: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2021-10-04 07:30:30.434078: W tensorflow/contrib/decent_q/utils/quantize_utils.cc:678] [DECENT_WARNING] Scale output of avg_pool node average_pooling2d/AvgPool to simulate DPU. Kernel size is 7 * 7
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:00 ETA:   0:00:09
 10% (2 of 20) |##                       | Elapsed Time: 0:00:01 ETA:   0:00:09
 15% (3 of 20) |###                      | Elapsed Time: 0:00:01 ETA:   0:00:08
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:01 ETA:   0:00:07
 25% (5 of 20) |######                   | Elapsed Time: 0:00:02 ETA:   0:00:07
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:02 ETA:   0:00:06
 35% (7 of 20) |########                 | Elapsed Time: 0:00:03 ETA:   0:00:06
 40% (8 of 20) |##########               | Elapsed Time: 0:00:03 ETA:   0:00:05
 45% (9 of 20) |###########              | Elapsed Time: 0:00:04 ETA:   0:00:05
 50% (10 of 20) |############            | Elapsed Time: 0:00:04 ETA:   0:00:04
 55% (11 of 20) |#############           | Elapsed Time: 0:00:05 ETA:   0:00:04
 60% (12 of 20) |##############          | Elapsed Time: 0:00:05 ETA:   0:00:03
 65% (13 of 20) |###############         | Elapsed Time: 0:00:06 ETA:   0:00:03
 70% (14 of 20) |################        | Elapsed Time: 0:00:06 ETA:   0:00:02
 75% (15 of 20) |##################      | Elapsed Time: 0:00:07 ETA:   0:00:02
 80% (16 of 20) |###################     | Elapsed Time: 0:00:07 ETA:   0:00:02
 85% (17 of 20) |####################    | Elapsed Time: 0:00:08 ETA:   0:00:01
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:08 ETA:   0:00:00
 95% (19 of 20) |######################  | Elapsed Time: 0:00:09 ETA:   0:00:00
100% (20 of 20) |########################| Elapsed Time: 0:00:09 Time:  0:00:09
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/cifar10/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb

##########################################################################
QUANTIZE miniResNet  on CIFAR10
##########################################################################
2021-10-04 07:30:44.913203: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2021-10-04 07:30:45.155807: W tensorflow/contrib/decent_q/utils/quantize_utils.cc:678] [DECENT_WARNING] Scale output of avg_pool node average_pooling2d/AvgPool to simulate DPU. Kernel size is 8 * 8
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:02 ETA:   0:00:38
 10% (2 of 20) |##                       | Elapsed Time: 0:00:03 ETA:   0:00:35
 15% (3 of 20) |###                      | Elapsed Time: 0:00:05 ETA:   0:00:32
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:07 ETA:   0:00:30
 25% (5 of 20) |######                   | Elapsed Time: 0:00:09 ETA:   0:00:28
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:11 ETA:   0:00:26
 35% (7 of 20) |########                 | Elapsed Time: 0:00:13 ETA:   0:00:24
 40% (8 of 20) |##########               | Elapsed Time: 0:00:15 ETA:   0:00:23
 45% (9 of 20) |###########              | Elapsed Time: 0:00:17 ETA:   0:00:21
 50% (10 of 20) |############            | Elapsed Time: 0:00:19 ETA:   0:00:19
 55% (11 of 20) |#############           | Elapsed Time: 0:00:21 ETA:   0:00:17
 60% (12 of 20) |##############          | Elapsed Time: 0:00:23 ETA:   0:00:15
 65% (13 of 20) |###############         | Elapsed Time: 0:00:25 ETA:   0:00:13
 70% (14 of 20) |################        | Elapsed Time: 0:00:27 ETA:   0:00:11
 75% (15 of 20) |##################      | Elapsed Time: 0:00:28 ETA:   0:00:09
 80% (16 of 20) |###################     | Elapsed Time: 0:00:30 ETA:   0:00:07
 85% (17 of 20) |####################    | Elapsed Time: 0:00:32 ETA:   0:00:05
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:34 ETA:   0:00:03
 95% (19 of 20) |######################  | Elapsed Time: 0:00:36 ETA:   0:00:01
100% (20 of 20) |########################| Elapsed Time: 0:00:38 Time:  0:00:38
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/cifar10/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb

##########################################################################
QUANTIZATION COMPLETED  on CIFAR10
##########################################################################


##########################################################################
EVALUATE QUANTIZED GRAPH of LeNet on CIFAR10
##########################################################################
2021-10-04 07:31:32.558213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:31:32.616461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:31:32.616686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:32.617588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:32.618534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:31:32.618821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:31:32.619952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:31:32.620824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:31:32.623346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:32.625123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:31:32.625413: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:31:32.646290: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:31:32.648182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7fc9d2cb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:31:32.648203: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:31:32.730884: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7fb1274f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:31:32.730926: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:31:32.733412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:31:32.733533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:32.733571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:32.733606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:31:32.733641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:31:32.733698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:31:32.733734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:31:32.733770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:32.738190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:31:32.738277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:32.742270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:31:32.742296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:31:32.742306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:31:32.745826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22482 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:31:34.055225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:34.173803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:34.681110: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.6880
 Top 5 accuracy with validation set: 0.9708
FINISHED!

##########################################################################
EVALUATE QUANTIZED GRAPH of miniVggNet  on CIFAR10
##########################################################################
2021-10-04 07:31:42.931917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:31:42.964873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:31:42.965090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:42.966004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:42.966868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:31:42.967132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:31:42.968147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:31:42.968922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:31:42.971297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:42.972744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:31:42.973047: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:31:42.994015: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:31:42.995659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559d326aade0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:31:42.995677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:31:43.069560: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559d30df8a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:31:43.069602: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:31:43.072114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:31:43.072231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:43.072270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:43.072304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:31:43.072339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:31:43.072373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:31:43.072416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:31:43.072458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:43.076707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:31:43.076794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:43.080754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:31:43.080778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:31:43.080789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:31:43.084499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22493 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:31:44.164103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:44.285613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:44.793639: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.8532
 Top 5 accuracy with validation set: 0.9908
FINISHED!

##############################################################################
EVALUATE QUANTIZED GRAPH of miniGoogleNet  on CIFAR10
##############################################################################
2021-10-04 07:31:52.792968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:31:52.839098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:31:52.839315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:52.840273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:52.841152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:31:52.841405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:31:52.842413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:31:52.843174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:31:52.845381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:52.846825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:31:52.847130: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:31:52.866875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:31:52.868481: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5625f6329800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:31:52.868500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:31:52.949889: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5625f624ddb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:31:52.949932: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:31:52.952554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:31:52.952669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:52.952707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:52.952744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:31:52.952779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:31:52.952813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:31:52.952863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:31:52.952918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:52.957212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:31:52.957298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:31:52.961303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:31:52.961321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:31:52.961328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:31:52.964299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22493 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:31:54.045381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:31:54.169206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:31:54.682380: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.8864
 Top 5 accuracy with validation set: 0.9964
FINISHED!

##########################################################################
EVALUATE QUANTIZED GRAPH of miniResNet  on CIFAR10
##########################################################################
2021-10-04 07:32:06.300874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:32:06.330273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:32:06.330502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:32:06.331794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:32:06.332679: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:32:06.332942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:32:06.333936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:32:06.334710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:32:06.336975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:32:06.338490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:32:06.338801: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:32:06.359537: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:32:06.361289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c73ce567d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:32:06.361330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:32:06.445521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c73b6a13b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:32:06.445572: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:32:06.448265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:32:06.448372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:32:06.448412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:32:06.448451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:32:06.448479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:32:06.448516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:32:06.448550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:32:06.448580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:32:06.452824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:32:06.452926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:32:06.456983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:32:06.457010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:32:06.457025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:32:06.460630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22492 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
2021-10-04 07:32:07.719693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:32:07.843019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:32:08.364146: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/cifar10
 Top 1 accuracy with validation set: 0.9286
 Top 5 accuracy with validation set: 0.9970
FINISHED!

##########################################################################
EVALUATE QUANTIZED GRAPH COMPLETED  on CIFAR10
##########################################################################


##########################################################################
COMPILE WITH Vitis AI on ZCU102: LeNet on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/LeNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/LeNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/LeNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/18 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 5285.83it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/23 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 23/23 [00:00<00:00, 535.34it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 786.04it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 786.55it/s]
[INFO] generate xmodel     :  0%|          | 0/20 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 15%|        | 3/20 [00:00<00:02,  7.94it/s]                   [INFO] generate xmodel     :100%|| 20/20 [00:00<00:00, 52.56it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/LeNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 28
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/LeNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 2b8126974945e0f559cb07f940a5d0c8, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU102: miniVggNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniVggNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/33 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 33/33 [00:00<00:00, 16949.80it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/34 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 2179.89it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 563.33it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 531.63it/s]
[INFO] generate xmodel     :  0%|          | 0/31 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 10%|         | 3/31 [00:00<00:01, 19.66it/s]                   [INFO] generate xmodel     :100%|| 31/31 [00:00<00:00, 200.40it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniVggNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 51
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/miniVggNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is e1b8c161b5f1290414d90c331af5ff98, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU102: miniGoogleNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniGoogleNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/94 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 94/94 [00:00<00:00, 22465.22it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/98 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 98/98 [00:00<00:00, 11498.64it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 281.83it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 386.00it/s]
[INFO] generate xmodel     :  0%|          | 0/95 [00:00<?, ?it/s]                           [INFO] generate xmodel     :100%|| 95/95 [00:00<00:00, 7634.19it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniGoogleNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 173
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/miniGoogleNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 4ef39051fdbaa5be022bdcebfa8340f1, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU102: miniResNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniResNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/458 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|| 458/458 [00:00<00:00, 25440.22it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/519 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|| 519/519 [00:00<00:00, 12045.53it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 67.22it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 67.46it/s]
[INFO] generate xmodel     :  0%|          | 0/516 [00:00<?, ?it/s]                          [INFO] generate xmodel     :100%|| 516/516 [00:00<00:00, 13816.87it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniResNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 798
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/miniResNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 7010936a1360ee3e0f955987bfbac028, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILATION COMPLETED  on CIFAR10 on ZCU102
##########################################################################


##########################################################################
COMPILE WITH Vitis AI on ZCU104: LeNet on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/LeNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/LeNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/LeNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/18 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 13942.28it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/23 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 23/23 [00:00<00:00, 729.12it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 853.80it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 793.65it/s]
[INFO] generate xmodel     :  0%|          | 0/20 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 15%|        | 3/20 [00:00<00:02,  7.85it/s]                   [INFO] generate xmodel     :100%|| 20/20 [00:00<00:00, 52.15it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/LeNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 28
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/LeNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 6e09a0068d090c31e28b1e6f00da0e72, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU104: miniVggNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniVggNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/33 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 33/33 [00:00<00:00, 16797.58it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/34 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 1991.90it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 553.56it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 541.36it/s]
[INFO] generate xmodel     :  0%|          | 0/31 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 10%|         | 3/31 [00:00<00:01, 19.72it/s]                   [INFO] generate xmodel     :100%|| 31/31 [00:00<00:00, 201.06it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniVggNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 51
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/miniVggNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 5410ee34a5bee6527a417e25af2bec9f, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU104: miniGoogleNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniGoogleNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/94 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 94/94 [00:00<00:00, 22742.53it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/98 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 98/98 [00:00<00:00, 11587.46it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 308.23it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 383.64it/s]
[INFO] generate xmodel     :  0%|          | 0/95 [00:00<?, ?it/s]                           [INFO] generate xmodel     :100%|| 95/95 [00:00<00:00, 7478.30it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniGoogleNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 173
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/miniGoogleNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is cbcf9a2407ba1ae96833d19e04205b21, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU104: miniResNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniResNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/458 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|| 458/458 [00:00<00:00, 24698.71it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/519 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|| 519/519 [00:00<00:00, 11709.44it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 66.89it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 66.81it/s]
[INFO] generate xmodel     :  0%|          | 0/516 [00:00<?, ?it/s]                          [INFO] generate xmodel     :100%|| 516/516 [00:00<00:00, 13228.25it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniResNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 798
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/miniResNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is f480971e38272f9c7472d03b66be2b9d, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILATION COMPLETED  on CIFAR10 on ZCU104
##########################################################################


##########################################################################
COMPILE WITH Vitis AI on VCK190: LeNet on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/LeNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/LeNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/LeNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/18 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 14443.75it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/23 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 23/23 [00:00<00:00, 725.80it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 625.83it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 779.92it/s]
[INFO] generate xmodel     :  0%|          | 0/20 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 15%|        | 3/20 [00:00<00:02,  7.68it/s]                   [INFO] generate xmodel     :100%|| 20/20 [00:00<00:00, 51.01it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/LeNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 28
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/LeNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 57ed87d0a3b34fb5875bfc9fa6031541, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/LeNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on VCK190: miniVggNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniVggNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniVggNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/33 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 33/33 [00:00<00:00, 17031.13it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/34 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 1984.75it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 906.39it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 962.84it/s]
[INFO] generate xmodel     :  0%|          | 0/31 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 10%|         | 3/31 [00:00<00:01, 20.39it/s]                   [INFO] generate xmodel     :100%|| 31/31 [00:00<00:00, 207.84it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniVggNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 51
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/miniVggNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is dfcf587753892b61bdd65ad308cbf696, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniVggNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on VCK190: miniGoogleNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniGoogleNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniGoogleNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/94 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 94/94 [00:00<00:00, 22809.64it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/98 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 98/98 [00:00<00:00, 12001.57it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 280.18it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 374.78it/s]
[INFO] generate xmodel     :  0%|          | 0/95 [00:00<?, ?it/s]                           [INFO] generate xmodel     :100%|| 95/95 [00:00<00:00, 7482.37it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniGoogleNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 173
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/miniGoogleNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 80c39ab7218590bafe0b1893df1b69ee, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniGoogleNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on VCK190: miniResNet  on CIFAR10
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniResNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/cifar10/miniResNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/458 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|| 458/458 [00:00<00:00, 25111.98it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/519 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|| 519/519 [00:00<00:00, 11860.97it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 68.53it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 67.07it/s]
[INFO] generate xmodel     :  0%|          | 0/516 [00:00<?, ?it/s]                          [INFO] generate xmodel     :100%|| 516/516 [00:00<00:00, 13743.69it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniResNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 798
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/miniResNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 0f55e29fcf0c87215a1606fe908229c1, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/cifar10/miniResNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILATION COMPLETED  on CIFAR10 on VCK190
##########################################################################

############################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for LeNet on FMNIST
############################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.

Model: "LeNet"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1_input (InputLayer)  [(None, 32, 32, 3)]       0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 50)        3800
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 50)        200
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 50)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 50)        0
_________________________________________________________________
flatten (Flatten)            (None, 12800)             0
_________________________________________________________________
dense (Dense)                (None, 500)               6400500
_________________________________________________________________
activation_2 (Activation)    (None, 500)               0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                5010
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0
=================================================================
Total params: 6,409,510
Trainable params: 6,409,410
Non-trainable params: 100
_________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_3/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


#################################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for miniVggNet  on FMNIST
#################################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.

Model: "miniVggNet"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1_input (InputLayer)  [(None, 32, 32, 3)]       0
_________________________________________________________________
conv2d (Conv2D)              (None, 32, 32, 32)        864
_________________________________________________________________
batch_normalization (BatchNo (None, 32, 32, 32)        128
_________________________________________________________________
activation (Activation)      (None, 32, 32, 32)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 32, 32)        9216
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 32)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 16, 64)        18432
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
activation_2 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        36864
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0
_________________________________________________________________
flatten (Flatten)            (None, 4096)              0
_________________________________________________________________
dense (Dense)                (None, 512)               2097664
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048
_________________________________________________________________
activation_4 (Activation)    (None, 512)               0
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0
_________________________________________________________________
dense_1 (Dense)              (None, 10)                5130
_________________________________________________________________
activation_5 (Activation)    (None, 10)                0
=================================================================
Total params: 2,170,986
Trainable params: 2,169,578
Non-trainable params: 1,408
_________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_5/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


#################################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for miniGoogleNet  on FMNIST
#################################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: "miniGoogleNet"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
conv2d_1_input (InputLayer)     [(None, 32, 32, 3)]  0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 32, 32, 96)   2688        conv2d_1_input[0][0]
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 32, 32, 96)   384         conv2d[0][0]
__________________________________________________________________________________________________
activation (Activation)         (None, 32, 32, 96)   0           batch_normalization[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 32)   3104        activation[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 32)   27680       activation[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 32)   0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 32, 32, 64)   0           activation_1[0][0]
                                                                 activation_2[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 32)   2080        concatenate[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 48)   27696       concatenate[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         conv2d_4[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 80)   0           activation_3[0][0]
                                                                 activation_4[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 15, 15, 80)   57680       concatenate_1[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 15, 15, 80)   320         conv2d_5[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 15, 15, 80)   0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 15, 15, 80)   0           concatenate_1[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 15, 15, 160)  0           activation_5[0][0]
                                                                 max_pooling2d[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 15, 15, 112)  18032       concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 15, 15, 48)   69168       concatenate_2[0][0]
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 15, 15, 112)  448         conv2d_6[0][0]
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 15, 15, 48)   192         conv2d_7[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 15, 15, 112)  0           batch_normalization_6[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 15, 15, 48)   0           batch_normalization_7[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 15, 15, 160)  0           activation_6[0][0]
                                                                 activation_7[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 15, 15, 96)   15456       concatenate_3[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 15, 15, 64)   92224       concatenate_3[0][0]
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 15, 15, 96)   384         conv2d_8[0][0]
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 15, 15, 64)   256         conv2d_9[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 15, 15, 96)   0           batch_normalization_8[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 15, 15, 160)  0           activation_8[0][0]
                                                                 activation_9[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 15, 15, 80)   12880       concatenate_4[0][0]              WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.


__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 15, 15, 80)   115280      concatenate_4[0][0]
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 15, 15, 80)   320         conv2d_10[0][0]
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 15, 15, 80)   320         conv2d_11[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 15, 15, 80)   0           batch_normalization_10[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 15, 15, 80)   0           batch_normalization_11[0][0]
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 15, 15, 160)  0           activation_10[0][0]
                                                                 activation_11[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 15, 15, 48)   7728        concatenate_5[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 15, 15, 96)   138336      concatenate_5[0][0]
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 15, 15, 48)   192         conv2d_12[0][0]
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 15, 15, 96)   384         conv2d_13[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 15, 15, 48)   0           batch_normalization_12[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 15, 15, 96)   0           batch_normalization_13[0][0]
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 15, 15, 144)  0           activation_12[0][0]
                                                                 activation_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 7, 7, 96)     124512      concatenate_6[0][0]
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 7, 7, 96)     384         conv2d_14[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 7, 7, 96)     0           batch_normalization_14[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 144)    0           concatenate_6[0][0]
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 7, 7, 240)    0           activation_14[0][0]
                                                                 max_pooling2d_1[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 7, 7, 176)    42416       concatenate_7[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 7, 7, 160)    345760      concatenate_7[0][0]
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 7, 7, 176)    704         conv2d_15[0][0]
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 7, 7, 160)    640         conv2d_16[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 7, 7, 176)    0           batch_normalization_15[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 7, 7, 160)    0           batch_normalization_16[0][0]
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 7, 7, 336)    0           activation_15[0][0]
                                                                 activation_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 7, 7, 176)    59312       concatenate_8[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 7, 7, 160)    484000      concatenate_8[0][0]
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 7, 7, 176)    704         conv2d_17[0][0]
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 7, 7, 160)    640         conv2d_18[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 7, 7, 176)    0           batch_normalization_17[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 7, 7, 160)    0           batch_normalization_18[0][0]
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 7, 7, 336)    0           activation_17[0][0]
                                                                 activation_18[0][0]
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 1, 1, 336)    0           concatenate_9[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1, 1, 336)    0           average_pooling2d[0][0]
__________________________________________________________________________________________________
flatten (Flatten)               (None, 336)          0           dropout[0][0]
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           3370        flatten[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 10)           0           dense[0][0]
==================================================================================================
Total params: 1,656,250
Trainable params: 1,652,826
Non-trainable params: 3,424
__________________________________________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_19/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


#################################################################################################
KERAS to TENSORFLOW GRAPH CONVERSION for miniResNet  on FMNIST
#################################################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: "resnet"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
conv2d_1_input (InputLayer)     [(None, 32, 32, 3)]  0
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 32, 32, 3)    12          conv2d_1_input[0][0]
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 32, 32, 64)   1728        batch_normalization[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d[0][0]
__________________________________________________________________________________________________
activation (Activation)         (None, 32, 32, 64)   0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   1024        activation[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2304        activation_1[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 64)   1024        activation_2[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 64)   4096        activation[0][0]
__________________________________________________________________________________________________
add (Add)                       (None, 32, 32, 64)   0           conv2d_3[0][0]
                                                                 conv2d_4[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add[0][0]
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   1024        activation_3[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2304        activation_4[0][0]
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 64)   1024        activation_5[0][0]
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]
                                                                 add[0][0]
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   1024        activation_6[0][0]
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2304        activation_7[0][0]
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 64)   1024        activation_8[0][0]
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_10[0][0]
                                                                 add_1[0][0]
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_2[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   1024        activation_9[0][0]
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_11[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 16)   2304        activation_10[0][0]
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 64)   1024        activation_11[0][0]
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 64)   0           conv2d_13[0][0]
                                                                 add_2[0][0]
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 16)   1024        activation_12[0][0]
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 16)   2304        activation_13[0][0]
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 64)   1024        activation_14[0][0]
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 64)   0           conv2d_16[0][0]
                                                                 add_3[0][0]
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         add_4[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 64)   0           batch_normalization_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 16)   1024        activation_15[0][0]
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 16)   2304        activation_16[0][0]
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 64)   1024        activation_17[0][0]
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 64)   0           conv2d_19[0][0]
                                                                 add_4[0][0]
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         add_5[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 64)   0           batch_normalization_19[0][0]
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 32, 32, 16)   1024        activation_18[0][0]
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 32, 32, 16)   2304        activation_19[0][0]
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 32, 32, 64)   1024        activation_20[0][0]
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 64)   0           conv2d_22[0][0]
                                                                 add_5[0][0]
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         add_6[0][0]
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 32, 32, 64)   0           batch_normalization_22[0][0]
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 32, 32, 16)   1024        activation_21[0][0]
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 32, 32, 16)   2304        activation_22[0][0]
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_24[0][0]
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 32, 32, 64)   1024        activation_23[0][0]
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 64)   0           conv2d_25[0][0]
                                                                 add_6[0][0]
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         add_7[0][0]
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 32, 32, 64)   0           batch_normalization_25[0][0]
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 32, 32, 16)   1024        activation_24[0][0]
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_26[0][0]
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 32, 32, 16)   2304        activation_25[0][0]
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 32, 32, 16)   0           batch_normalization_27[0][0]
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 32, 32, 64)   1024        activation_26[0][0]
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 64)   0           conv2d_28[0][0]
                                                                 add_7[0][0]
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 32, 32, 64)   256         add_8[0][0]
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 32, 32, 64)   0           batch_normalization_28[0][0]
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 32, 32, 32)   2048        activation_27[0][0]
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 32, 32, 32)   128         conv2d_29[0][0]
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 32, 32, 32)   0           batch_normalization_29[0][0]
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 32)   9216        activation_28[0][0]
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 128)  4096        activation_29[0][0]
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 16, 16, 128)  8192        activation_27[0][0]
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 16, 128)  0           conv2d_31[0][0]
                                                                 conv2d_32[0][0]
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_9[0][0]
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 128)  0           batch_normalization_31[0][0]
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 16, 16, 32)   4096        activation_30[0][0]
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 16, 16, 32)   9216        activation_31[0][0]
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_33[0][0]
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 128)  4096        activation_32[0][0]
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 128)  0           conv2d_35[0][0]
                                                                 add_9[0][0]
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 128)  0           batch_normalization_34[0][0]
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 16, 16, 32)   4096        activation_33[0][0]
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_35[0][0]
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 16, 16, 32)   9216        activation_34[0][0]
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 16, 16, 128)  4096        activation_35[0][0]
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 128)  0           conv2d_38[0][0]
                                                                 add_10[0][0]
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 128)  0           batch_normalization_37[0][0]
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 16, 16, 32)   4096        activation_36[0][0]
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 16, 16, 32)   128         conv2d_39[0][0]
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           batch_normalization_38[0][0]
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 16, 16, 32)   9216        activation_37[0][0]
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 16, 16, 32)   128         conv2d_40[0][0]
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_39[0][0]
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 16, 16, 128)  4096        activation_38[0][0]
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 128)  0           conv2d_41[0][0]
                                                                 add_11[0][0]
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 16, 16, 128)  0           batch_normalization_40[0][0]
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 16, 16, 32)   4096        activation_39[0][0]
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 16, 16, 32)   128         conv2d_42[0][0]
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_41[0][0]
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 16, 16, 32)   9216        activation_40[0][0]
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 16, 16, 32)   128         conv2d_43[0][0]
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 16, 16, 32)   0           batch_normalization_42[0][0]
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 16, 16, 128)  4096        activation_41[0][0]
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_44[0][0]
                                                                 add_12[0][0]
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 16, 16, 128)  0           batch_normalization_43[0][0]
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 16, 16, 32)   4096        activation_42[0][0]
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 16, 16, 32)   128         conv2d_45[0][0]
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 16, 16, 32)   0           batch_normalization_44[0][0]
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 16, 16, 32)   9216        activation_43[0][0]
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_46[0][0]
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 16, 16, 128)  4096        activation_44[0][0]
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 128)  0           conv2d_47[0][0]
                                                                 add_13[0][0]
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 16, 16, 128)  0           batch_normalization_46[0][0]
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 16, 16, 32)   4096        activation_45[0][0]
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_48[0][0]
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 16, 16, 32)   9216        activation_46[0][0]
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_49[0][0]
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 16, 16, 128)  4096        activation_47[0][0]
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 128)  0           conv2d_50[0][0]
                                                                 add_14[0][0]
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 16, 16, 128)  0           batch_normalization_49[0][0]
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 16, 16, 32)   4096        activation_48[0][0]
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_51[0][0]
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 16, 16, 32)   9216        activation_49[0][0]
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv2d_52[0][0]
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_51[0][0]
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 16, 16, 128)  4096        activation_50[0][0]
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 128)  0           conv2d_53[0][0]
                                                                 add_15[0][0]
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 16, 16, 128)  512         add_16[0][0]
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 16, 16, 128)  0           batch_normalization_52[0][0]
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 16, 16, 32)   4096        activation_51[0][0]
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 16, 16, 32)   0           batch_normalization_53[0][0]
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 16, 16, 32)   9216        activation_52[0][0]
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 16, 16, 32)   0           batch_normalization_54[0][0]
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 16, 16, 128)  4096        activation_53[0][0]
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 128)  0           conv2d_56[0][0]
                                                                 add_16[0][0]
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 16, 16, 128)  512         add_17[0][0]
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 16, 16, 128)  0           batch_normalization_55[0][0]
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 16, 16, 64)   8192        activation_54[0][0]
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 16, 16, 64)   256         conv2d_57[0][0]
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 8, 8, 64)     36864       activation_55[0][0]
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_57[0][0]
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 8, 8, 256)    16384       activation_56[0][0]
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 8, 8, 256)    32768       activation_54[0][0]
__________________________________________________________________________________________________
add_18 (Add)                    (None, 8, 8, 256)    0           conv2d_59[0][0]
                                                                 conv2d_60[0][0]
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 8, 8, 256)    0           batch_normalization_58[0][0]
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 8, 8, 64)     16384       activation_57[0][0]
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 8, 8, 64)     0           batch_normalization_59[0][0]
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 8, 8, 64)     36864       activation_58[0][0]
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 8, 8, 64)     0           batch_normalization_60[0][0]
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 8, 8, 256)    16384       activation_59[0][0]
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 8, 256)    0           conv2d_63[0][0]
                                                                 add_18[0][0]
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        add_19[0][0]
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 8, 8, 64)     16384       activation_60[0][0]
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 8, 8, 64)     256         conv2d_64[0][0]
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 8, 8, 64)     0           batch_normalization_62[0][0]
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 8, 8, 64)     36864       activation_61[0][0]
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 8, 8, 64)     256         conv2d_65[0][0]
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 8, 8, 64)     0           batch_normalization_63[0][0]
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 8, 8, 256)    16384       activation_62[0][0]
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 8, 256)    0           conv2d_66[0][0]
                                                                 add_19[0][0]
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        add_20[0][0]
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 8, 8, 64)     16384       activation_63[0][0]
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 8, 8, 64)     256         conv2d_67[0][0]
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 8, 8, 64)     0           batch_normalization_65[0][0]
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 8, 8, 64)     36864       activation_64[0][0]
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 8, 8, 64)     256         conv2d_68[0][0]
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 8, 8, 64)     0           batch_normalization_66[0][0]
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 8, 8, 256)    16384       activation_65[0][0]
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 256)    0           conv2d_69[0][0]
                                                                 add_20[0][0]
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        add_21[0][0]
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 8, 8, 64)     16384       activation_66[0][0]
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 8, 8, 64)     256         conv2d_70[0][0]
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 8, 8, 64)     0           batch_normalization_68[0][0]
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 8, 8, 64)     36864       activation_67[0][0]
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 8, 8, 64)     256         conv2d_71[0][0]
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 8, 8, 64)     0           batch_normalization_69[0][0]
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 8, 8, 256)    16384       activation_68[0][0]
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 256)    0           conv2d_72[0][0]
                                                                 add_21[0][0]
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        add_22[0][0]
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 8, 8, 64)     16384       activation_69[0][0]
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 8, 8, 64)     256         conv2d_73[0][0]
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 8, 8, 64)     0           batch_normalization_71[0][0]
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 8, 8, 64)     36864       activation_70[0][0]
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 8, 8, 64)     256         conv2d_74[0][0]
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 8, 8, 64)     0           batch_normalization_72[0][0]
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 8, 8, 256)    16384       activation_71[0][0]
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 256)    0           conv2d_75[0][0]
                                                                 add_22[0][0]
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        add_23[0][0]
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 8, 8, 64)     16384       activation_72[0][0]
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 8, 8, 64)     256         conv2d_76[0][0]
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 8, 8, 64)     0           batch_normalization_74[0][0]
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 8, 8, 64)     36864       activation_73[0][0]
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 8, 8, 64)     256         conv2d_77[0][0]
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 8, 8, 64)     0           batch_normalization_75[0][0]
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 8, 8, 256)    16384       activation_74[0][0]
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 256)    0           conv2d_78[0][0]
                                                                 add_23[0][0]
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 8, 8, 256)    1024        add_24[0][0]
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 8, 8, 256)    0           batch_normalization_76[0][0]
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 8, 8, 64)     16384       activation_75[0][0]
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 8, 8, 64)     256         conv2d_79[0][0]
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 8, 8, 64)     0           batch_normalization_77[0][0]
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 8, 8, 64)     36864       activation_76[0][0]
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 8, 8, 64)     256         conv2d_80[0][0]
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 8, 8, 64)     0           batch_normalization_78[0][0]
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 8, 8, 256)    16384       activation_77[0][0]
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 256)    0           conv2d_81[0][0]
                                                                 add_24[0][0]
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 8, 8, 256)    1024        add_25[0][0]
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 8, 8, 256)    0           batch_normalization_79[0][0]
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 8, 8, 64)     16384       activation_78[0][0]
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 8, 8, 64)     256         conv2d_82[0][0]
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 8, 8, 64)     0           batch_normalization_80[0][0]
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 8, 8, 64)     36864       activation_79[0][0]
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 8, 8, 64)     256         conv2d_83[0][0]
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 8, 8, 64)     0           batch_normalization_81[0][0]
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 8, 8, 256)    16384       activation_80[0][0]
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 256)    0           conv2d_84[0][0]
                                                                 add_25[0][0]                     WARNING:tensorflow:From code/Keras2TF.py:73: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.


__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 8, 8, 256)    1024        add_26[0][0]
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 8, 8, 256)    0           batch_normalization_82[0][0]
__________________________________________________________________________________________________
average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_81[0][0]
__________________________________________________________________________________________________
flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           2570        flatten[0][0]
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 10)           0           dense[0][0]
==================================================================================================
Total params: 886,102
Trainable params: 873,872
Non-trainable params: 12,230
__________________________________________________________________________________________________

 TF input node name:
[<tf.Tensor 'conv2d_1_input:0' shape=(?, 32, 32, 3) dtype=float32>]

 TF output node name:
[<tf.Tensor 'activation_82/Softmax:0' shape=(?, 10) dtype=float32>]

FINISHED CREATING TF FILES


##########################################################################
FREEZE GRAPH of LeNet on FMNIST
##########################################################################
rm: cannot remove './build/freeze/fmnist/Lenet/*': No such file or directory
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:34:03.030123 139898970445632 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:34:03.033178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:34:03.080163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:03.080351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:03.081404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:03.082394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:03.082665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:03.083916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:03.084847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:03.087702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:03.089465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:03.089850: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:34:03.111852: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:34:03.113789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559e60ac7390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:03.113806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:34:03.172334: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559e5f526430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:03.172375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:34:03.174856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:03.174926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:03.174948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:03.174976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:03.175006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:03.175029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:03.175048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:03.175068: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:03.179269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:03.179332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:03.182701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:34:03.182721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:34:03.182730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:34:03.186373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22556 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/fmnist/LeNet/float_model.ckpt
I1004 07:34:03.257825 139898970445632 saver.py:1284] Restoring parameters from ./build/tf_chkpts/fmnist/LeNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:34:04.190138 139898970445632 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:34:04.190586 139898970445632 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 10 variables.
I1004 07:34:04.269306 139898970445632 graph_util_impl.py:334] Froze 10 variables.
INFO:tensorflow:Converted 10 variables to const ops.
I1004 07:34:04.318815 139898970445632 graph_util_impl.py:394] Converted 10 variables to const ops.
Loaded meta graph file './build/tf_chkpts/fmnist/LeNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of LeNet  on FMNIST
##########################################################################
Op types used: 14 Const, 10 Identity, 3 BiasAdd, 2 MatMul, 2 Relu, 1 Conv2D, 1 FusedBatchNormV3, 1 MaxPool, 1 Pack, 1 Placeholder, 1 Reshape, 1 Shape, 1 Softmax, 1 StridedSlice

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_3/Softmax, op=Softmax)

##########################################################################
FREEZE GRAPH of miniVggNet  on FMNIST
##########################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:34:08.391296 140194180835136 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:34:08.394531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:34:08.459744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:08.459931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:08.460933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:08.461924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:08.462187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:08.463439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:08.464375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:08.467261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:08.468691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:08.469008: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:34:08.490760: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:34:08.493124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fd0a5ed510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:08.493139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:34:08.565725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fd08fe9860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:08.565768: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:34:08.568281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:08.568364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:08.568386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:08.568405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:08.568424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:08.568443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:08.568462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:08.568482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:08.573019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:08.573089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:08.576423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:34:08.576447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:34:08.576458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:34:08.580810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22556 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/fmnist/miniVggNet/float_model.ckpt
I1004 07:34:08.756483 140194180835136 saver.py:1284] Restoring parameters from ./build/tf_chkpts/fmnist/miniVggNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:34:09.708706 140194180835136 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:34:09.709105 140194180835136 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 28 variables.
I1004 07:34:09.763174 140194180835136 graph_util_impl.py:334] Froze 28 variables.
INFO:tensorflow:Converted 28 variables to const ops.
I1004 07:34:09.778314 140194180835136 graph_util_impl.py:394] Converted 28 variables to const ops.
Loaded meta graph file './build/tf_chkpts/fmnist/miniVggNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of miniVggNet on FMNIST
##########################################################################
Op types used: 33 Const, 31 Identity, 5 Relu, 4 Conv2D, 4 FusedBatchNormV3, 3 Mul, 2 BiasAdd, 2 MatMul, 2 MaxPool, 2 AddV2, 1 Sub, 1 StridedSlice, 1 Softmax, 1 Shape, 1 Rsqrt, 1 Reshape, 1 Placeholder, 1 Pack

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_5/Softmax, op=Softmax)
##########################################################################
FREEZE GRAPH of miniGoogleNet  on FMNIST
##########################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:34:13.673562 140506876811072 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:34:13.678105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:34:13.728430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:13.728634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:13.729720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:13.730884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:13.731225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:13.732748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:13.733946: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:13.737424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:13.739120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:13.739458: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:34:13.761373: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:34:13.764272: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ddfd03e1c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:13.764303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:34:13.839580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ddfba9d420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:13.839622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:34:13.842143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:13.842217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:13.842239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:13.842259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:13.842279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:13.842298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:13.842317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:13.842337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:13.846429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:13.846500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:13.849801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:34:13.849824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:34:13.849835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:34:13.854043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22556 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/fmnist/miniGoogleNet/float_model.ckpt
I1004 07:34:14.241097 140506876811072 saver.py:1284] Restoring parameters from ./build/tf_chkpts/fmnist/miniGoogleNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:34:15.399172 140506876811072 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:34:15.399574 140506876811072 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 116 variables.
I1004 07:34:15.543150 140506876811072 graph_util_impl.py:334] Froze 116 variables.
INFO:tensorflow:Converted 116 variables to const ops.
I1004 07:34:15.558731 140506876811072 graph_util_impl.py:394] Converted 116 variables to const ops.
Loaded meta graph file './build/tf_chkpts/fmnist/miniGoogleNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of miniGoogleNet  on FMNIST
##########################################################################
Op types used: 130 Const, 117 Identity, 20 BiasAdd, 19 Conv2D, 19 FusedBatchNormV3, 19 Relu, 10 ConcatV2, 2 MaxPool, 1 AvgPool, 1 MatMul, 1 Pack, 1 Placeholder, 1 Reshape, 1 Shape, 1 Softmax, 1 StridedSlice

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_19/Softmax, op=Softmax)
##########################################################################
FREEZE GRAPH of miniResNet  on FMNIST
##########################################################################
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1004 07:34:19.534000 140094048483136 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2021-10-04 07:34:19.555294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-10-04 07:34:19.619283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:19.619483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:19.620554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:19.621518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:19.621795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:19.623042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:19.624024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:19.627121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:19.628529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:19.628843: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-10-04 07:34:19.651048: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499950000 Hz
2021-10-04 07:34:19.652989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5588db0f91f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:19.653022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-10-04 07:34:19.725319: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5588d9eab430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-10-04 07:34:19.725360: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P6000, Compute Capability 6.1
2021-10-04 07:34:19.727790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Quadro P6000 major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:65:00.0
2021-10-04 07:34:19.727868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:19.727890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2021-10-04 07:34:19.727909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2021-10-04 07:34:19.727928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2021-10-04 07:34:19.727947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2021-10-04 07:34:19.727966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2021-10-04 07:34:19.727986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-10-04 07:34:19.732170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-10-04 07:34:19.732236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2021-10-04 07:34:19.735534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-10-04 07:34:19.735557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2021-10-04 07:34:19.735567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2021-10-04 07:34:19.739760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22556 MB memory) -> physical GPU (device: 0, name: Quadro P6000, pci bus id: 0000:65:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from ./build/tf_chkpts/fmnist/miniResNet/float_model.ckpt
I1004 07:34:21.131135 140094048483136 saver.py:1284] Restoring parameters from ./build/tf_chkpts/fmnist/miniResNet/float_model.ckpt
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1004 07:34:22.907982 140094048483136 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/tools/freeze_graph.py:226: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W1004 07:34:22.908388 140094048483136 deprecation.py:323] From /opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 419 variables.
I1004 07:34:23.436354 140094048483136 graph_util_impl.py:334] Froze 419 variables.
INFO:tensorflow:Converted 419 variables to const ops.
I1004 07:34:23.474746 140094048483136 graph_util_impl.py:394] Converted 419 variables to const ops.
Loaded meta graph file './build/tf_chkpts/fmnist/miniResNet/float_model.ckpt.meta

##########################################################################
INSPECT FROZEN GRAPH of miniResNet
##########################################################################
Op types used: 423 Const, 419 Identity, 85 Conv2D, 83 FusedBatchNormV3, 82 Relu, 27 AddV2, 1 AvgPool, 1 BiasAdd, 1 MatMul, 1 Pack, 1 Placeholder, 1 Reshape, 1 Shape, 1 Softmax, 1 StridedSlice

Found 1 possible inputs: (name=conv2d_1_input, type=float(1), shape=[?,32,32,3])
Found 1 possible outputs: (name=activation_82/Softmax, op=Softmax)

##########################################################################
FREEZE GRAPH COMPLETED
##########################################################################


##########################################################################
EVALUATE FROZEN GRAPH of LeNet on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9126
 Top 5 accuracy with test dataset: 0.9978
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH of miniVggNet  on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9384
 Top 5 accuracy with test dataset: 0.9994
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH of GoogleNet  on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9068
 Top 5 accuracy with test dataset: 0.9976
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH of ResNet  on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9388
 Top 5 accuracy with test dataset: 0.9994
FINISHED!

##########################################################################
EVALUATE FROZEN GRAPH COMPLETED  on FMNIST
##########################################################################


##########################################################################
QUANTIZE LeNet on FMNIST
##########################################################################
2021-10-04 07:35:56.701003: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:00 ETA:   0:00:03
 10% (2 of 20) |##                       | Elapsed Time: 0:00:00 ETA:   0:00:06
 15% (3 of 20) |###                      | Elapsed Time: 0:00:01 ETA:   0:00:06
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:01 ETA:   0:00:07
 25% (5 of 20) |######                   | Elapsed Time: 0:00:02 ETA:   0:00:08
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:02 ETA:   0:00:07
 35% (7 of 20) |########                 | Elapsed Time: 0:00:03 ETA:   0:00:07
 40% (8 of 20) |##########               | Elapsed Time: 0:00:04 ETA:   0:00:06
 45% (9 of 20) |###########              | Elapsed Time: 0:00:04 ETA:   0:00:06
 50% (10 of 20) |############            | Elapsed Time: 0:00:05 ETA:   0:00:05
 55% (11 of 20) |#############           | Elapsed Time: 0:00:05 ETA:   0:00:04
 60% (12 of 20) |##############          | Elapsed Time: 0:00:06 ETA:   0:00:04
 65% (13 of 20) |###############         | Elapsed Time: 0:00:06 ETA:   0:00:03
 70% (14 of 20) |################        | Elapsed Time: 0:00:07 ETA:   0:00:03
 75% (15 of 20) |##################      | Elapsed Time: 0:00:07 ETA:   0:00:02
 80% (16 of 20) |###################     | Elapsed Time: 0:00:08 ETA:   0:00:02
 85% (17 of 20) |####################    | Elapsed Time: 0:00:08 ETA:   0:00:01
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:09 ETA:   0:00:01
 95% (19 of 20) |######################  | Elapsed Time: 0:00:09 ETA:   0:00:00
100% (20 of 20) |########################| Elapsed Time: 0:00:10 Time:  0:00:10
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/fmnist/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/fmnist/LeNet/quantize_eval_model.pb

##########################################################################
QUANTIZE miniVggNet  on FMNIST
##########################################################################
2021-10-04 07:36:11.727790: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:00 ETA:   0:00:03
 10% (2 of 20) |##                       | Elapsed Time: 0:00:00 ETA:   0:00:03
 15% (3 of 20) |###                      | Elapsed Time: 0:00:00 ETA:   0:00:03
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:00 ETA:   0:00:02
 25% (5 of 20) |######                   | Elapsed Time: 0:00:00 ETA:   0:00:02
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:01 ETA:   0:00:02
 35% (7 of 20) |########                 | Elapsed Time: 0:00:01 ETA:   0:00:02
 40% (8 of 20) |##########               | Elapsed Time: 0:00:01 ETA:   0:00:02
 45% (9 of 20) |###########              | Elapsed Time: 0:00:01 ETA:   0:00:01
 50% (10 of 20) |############            | Elapsed Time: 0:00:01 ETA:   0:00:01
 55% (11 of 20) |#############           | Elapsed Time: 0:00:01 ETA:   0:00:01
 60% (12 of 20) |##############          | Elapsed Time: 0:00:01 ETA:   0:00:01
 65% (13 of 20) |###############         | Elapsed Time: 0:00:02 ETA:   0:00:01
 70% (14 of 20) |################        | Elapsed Time: 0:00:02 ETA:   0:00:00
 75% (15 of 20) |##################      | Elapsed Time: 0:00:02 ETA:   0:00:00
 80% (16 of 20) |###################     | Elapsed Time: 0:00:02 ETA:   0:00:00
 85% (17 of 20) |####################    | Elapsed Time: 0:00:02 ETA:   0:00:00
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:02 ETA:   0:00:00
 95% (19 of 20) |######################  | Elapsed Time: 0:00:03 ETA:   0:00:00
100% (20 of 20) |########################| Elapsed Time: 0:00:03 Time:  0:00:03
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/fmnist/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb

##########################################################################
QUANTIZE miniGoogleNet  on FMNIST
##########################################################################
2021-10-04 07:36:19.617136: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2021-10-04 07:36:19.833429: W tensorflow/contrib/decent_q/utils/quantize_utils.cc:678] [DECENT_WARNING] Scale output of avg_pool node average_pooling2d/AvgPool to simulate DPU. Kernel size is 7 * 7
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:00 ETA:   0:00:09
 10% (2 of 20) |##                       | Elapsed Time: 0:00:01 ETA:   0:00:09
 15% (3 of 20) |###                      | Elapsed Time: 0:00:01 ETA:   0:00:08
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:02 ETA:   0:00:08
 25% (5 of 20) |######                   | Elapsed Time: 0:00:02 ETA:   0:00:07
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:02 ETA:   0:00:06
 35% (7 of 20) |########                 | Elapsed Time: 0:00:03 ETA:   0:00:06
 40% (8 of 20) |##########               | Elapsed Time: 0:00:04 ETA:   0:00:05
 45% (9 of 20) |###########              | Elapsed Time: 0:00:04 ETA:   0:00:05
 50% (10 of 20) |############            | Elapsed Time: 0:00:04 ETA:   0:00:04
 55% (11 of 20) |#############           | Elapsed Time: 0:00:05 ETA:   0:00:04
 60% (12 of 20) |##############          | Elapsed Time: 0:00:05 ETA:   0:00:03
 65% (13 of 20) |###############         | Elapsed Time: 0:00:06 ETA:   0:00:03
 70% (14 of 20) |################        | Elapsed Time: 0:00:06 ETA:   0:00:02
 75% (15 of 20) |##################      | Elapsed Time: 0:00:07 ETA:   0:00:02
 80% (16 of 20) |###################     | Elapsed Time: 0:00:07 ETA:   0:00:01
 85% (17 of 20) |####################    | Elapsed Time: 0:00:08 ETA:   0:00:01
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:08 ETA:   0:00:00
 95% (19 of 20) |######################  | Elapsed Time: 0:00:09 ETA:   0:00:00
100% (20 of 20) |########################| Elapsed Time: 0:00:09 Time:  0:00:09
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/fmnist/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb

##########################################################################
QUANTIZE miniResNet  on FMNIST
##########################################################################
2021-10-04 07:36:34.520692: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2021-10-04 07:36:34.774803: W tensorflow/contrib/decent_q/utils/quantize_utils.cc:678] [DECENT_WARNING] Scale output of avg_pool node average_pooling2d/AvgPool to simulate DPU. Kernel size is 8 * 8
N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--
  5% (1 of 20) |#                        | Elapsed Time: 0:00:02 ETA:   0:00:39
 10% (2 of 20) |##                       | Elapsed Time: 0:00:03 ETA:   0:00:35
 15% (3 of 20) |###                      | Elapsed Time: 0:00:05 ETA:   0:00:32
 20% (4 of 20) |#####                    | Elapsed Time: 0:00:07 ETA:   0:00:30
 25% (5 of 20) |######                   | Elapsed Time: 0:00:09 ETA:   0:00:28
 30% (6 of 20) |#######                  | Elapsed Time: 0:00:11 ETA:   0:00:28
 35% (7 of 20) |########                 | Elapsed Time: 0:00:13 ETA:   0:00:26
 40% (8 of 20) |##########               | Elapsed Time: 0:00:15 ETA:   0:00:23
 45% (9 of 20) |###########              | Elapsed Time: 0:00:17 ETA:   0:00:22
 50% (10 of 20) |############            | Elapsed Time: 0:00:19 ETA:   0:00:20
 55% (11 of 20) |#############           | Elapsed Time: 0:00:21 ETA:   0:00:17
 60% (12 of 20) |##############          | Elapsed Time: 0:00:23 ETA:   0:00:15
 65% (13 of 20) |###############         | Elapsed Time: 0:00:25 ETA:   0:00:13
 70% (14 of 20) |################        | Elapsed Time: 0:00:27 ETA:   0:00:11
 75% (15 of 20) |##################      | Elapsed Time: 0:00:29 ETA:   0:00:09
 80% (16 of 20) |###################     | Elapsed Time: 0:00:31 ETA:   0:00:08
 85% (17 of 20) |####################    | Elapsed Time: 0:00:33 ETA:   0:00:05
 90% (18 of 20) |#####################   | Elapsed Time: 0:00:35 ETA:   0:00:03
 95% (19 of 20) |######################  | Elapsed Time: 0:00:36 ETA:   0:00:01
100% (20 of 20) |########################| Elapsed Time: 0:00:38 Time:  0:00:38
script running on folder  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code
CALIB DIR  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/code/../build/dataset/fmnist/calib
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: skip create deploy_model.pb
********************* Quantization Summary *********************
INFO: Output:
  quantize_eval_model: ../build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb

##########################################################################
QUANTIZATION COMPLETED  on FMNIST
##########################################################################


##########################################################################
EVALUATE QUANTIZED GRAPH of LeNet on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9154
 Top 5 accuracy with test dataset: 0.9982
FINISHED!

##########################################################################
EVALUATE QUANTIZED GRAPH of miniVggNet  on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9418
 Top 5 accuracy with test dataset: 0.9996
FINISHED!

##############################################################################
EVALUATE QUANTIZED GRAPH of miniGoogleNet  on FMNIST
##############################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9094
 Top 5 accuracy with test dataset: 0.9976
FINISHED!

##########################################################################
EVALUATE QUANTIZED GRAPH of miniResNet  on FMNIST
##########################################################################

 eval_graph.py runs from  /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/dataset/fmnist
 Top 1 accuracy with test dataset: 0.9344
 Top 5 accuracy with test dataset: 0.9984
FINISHED!

##########################################################################
EVALUATE QUANTIZED GRAPH COMPLETED  on FMNIST
##########################################################################


##########################################################################
COMPILE WITH Vitis  on VCK190: LeNet on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/LeNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/LeNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/LeNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/18 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 13746.81it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/23 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 23/23 [00:00<00:00, 733.36it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 833.44it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 775.07it/s]
[INFO] generate xmodel     :  0%|          | 0/20 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 15%|        | 3/20 [00:00<00:02,  7.64it/s]                   [INFO] generate xmodel     :100%|| 20/20 [00:00<00:00, 50.80it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/LeNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 28
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/LeNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 83f35c5741439e8d0fca091254ae5d13, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on VCK190: miniVggNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniVggNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/33 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 33/33 [00:00<00:00, 17081.58it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/34 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 2691.24it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 786.33it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 738.26it/s]
[INFO] generate xmodel     :  0%|          | 0/31 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 10%|         | 3/31 [00:00<00:01, 19.21it/s]                   [INFO] generate xmodel     :100%|| 31/31 [00:00<00:00, 195.46it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniVggNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 51
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/miniVggNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is f7c67168b162912dfce5b8f4518d67ed, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on VCK190: miniGoogleNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniGoogleNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/94 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 94/94 [00:00<00:00, 23053.71it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/98 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 98/98 [00:00<00:00, 11497.35it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 292.72it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 381.80it/s]
[INFO] generate xmodel     :  0%|          | 0/95 [00:00<?, ?it/s]                           [INFO] generate xmodel     :100%|| 95/95 [00:00<00:00, 7775.41it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniGoogleNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 173
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/miniGoogleNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 1b00432dc5cce0fac89564e02c853110, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on VCK190: miniResNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniResNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/458 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|| 458/458 [00:00<00:00, 24400.05it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/519 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|| 519/519 [00:00<00:00, 11724.70it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 64.76it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 62.81it/s]
[INFO] generate xmodel     :  0%|          | 0/516 [00:00<?, ?it/s]                          [INFO] generate xmodel     :100%|| 516/516 [00:00<00:00, 12801.28it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniResNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCVDX8G_ISA1_C32B3
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 798
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/miniResNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is a9d7221f1c7d8ec5cd312674446d6230, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILATION COMPLETED  on FMNIST on VCK190
##########################################################################


##########################################################################
COMPILE WITH Vitis AI on ZCU102: LeNet on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/LeNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/LeNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/LeNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/18 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 13282.45it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/23 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 23/23 [00:00<00:00, 742.47it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 842.91it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 790.98it/s]
[INFO] generate xmodel     :  0%|          | 0/20 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 15%|        | 3/20 [00:00<00:02,  7.88it/s]                   [INFO] generate xmodel     :100%|| 20/20 [00:00<00:00, 52.39it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/LeNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 28
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/LeNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 1ddea1260b0faa274c5d897bc3ad6ad0, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU102: miniVggNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniVggNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/33 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 33/33 [00:00<00:00, 16960.18it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/34 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 2158.25it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 564.40it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 532.28it/s]
[INFO] generate xmodel     :  0%|          | 0/31 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 10%|         | 3/31 [00:00<00:01, 19.26it/s]                   [INFO] generate xmodel     :100%|| 31/31 [00:00<00:00, 196.40it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniVggNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 51
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/miniVggNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 4775f77645dab834d63dbb780f8cd53f, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU102: miniGoogleNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniGoogleNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/94 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 94/94 [00:00<00:00, 22985.17it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/98 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 98/98 [00:00<00:00, 11542.55it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 295.33it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 386.20it/s]
[INFO] generate xmodel     :  0%|          | 0/95 [00:00<?, ?it/s]                           [INFO] generate xmodel     :100%|| 95/95 [00:00<00:00, 7466.95it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniGoogleNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu

[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 173
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/miniGoogleNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 063af63c5258352249741cae2045ef9c, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU102: miniResNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniResNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/458 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|| 458/458 [00:00<00:00, 24393.23it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/519 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|| 519/519 [00:00<00:00, 11717.89it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 67.17it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 67.25it/s]
[INFO] generate xmodel     :  0%|          | 0/516 [00:00<?, ?it/s]                          [INFO] generate xmodel     :100%|| 516/516 [00:00<00:00, 13513.03it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniResNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 798
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/miniResNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 90c0bbe130ef7f2e7e949718ca6d3b2f, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILATION COMPLETED on ZCU102 on FMNIST
##########################################################################


##########################################################################
COMPILE WITH Vitis AI on ZCU104: LeNet on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/LeNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/LeNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/LeNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/18 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 18/18 [00:00<00:00, 13327.00it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/23 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 23/23 [00:00<00:00, 737.55it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 1009.95it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 1048.10it/s]
[INFO] generate xmodel     :  0%|          | 0/20 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 15%|        | 3/20 [00:00<00:02,  7.81it/s]                   [INFO] generate xmodel     :100%|| 20/20 [00:00<00:00, 51.91it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/LeNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 28
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/LeNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is b0588d2e29bf8f168100b4bdecd99cd6, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/LeNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU104: miniVggNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniVggNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniVggNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/33 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 33/33 [00:00<00:00, 16648.07it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/34 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 34/34 [00:00<00:00, 1979.21it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 607.43it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 574.16it/s]
[INFO] generate xmodel     :  0%|          | 0/31 [00:00<?, ?it/s]                           [INFO] generate xmodel     : 10%|         | 3/31 [00:00<00:01, 19.87it/s]                   [INFO] generate xmodel     :100%|| 31/31 [00:00<00:00, 202.50it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniVggNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 51
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/miniVggNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 81a18c7a6c47ffef4ec0fef39de7dd2d, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniVggNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU104: miniGoogleNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniGoogleNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniGoogleNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/94 [00:00<?, ?it/s]                           [INFO] parse raw model     :100%|| 94/94 [00:00<00:00, 22276.09it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/98 [00:00<?, ?it/s]                           [INFO] infer shape (NHWC)  :100%|| 98/98 [00:00<00:00, 11663.41it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 294.79it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 389.85it/s]
[INFO] generate xmodel     :  0%|          | 0/95 [00:00<?, ?it/s]                           [INFO] generate xmodel     :100%|| 95/95 [00:00<00:00, 7499.98it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniGoogleNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 173
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/miniGoogleNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is c5a376c93780c023c9e5e2b2d955d7ee, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniGoogleNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILE WITH Vitis AI on ZCU104: miniResNet  on FMNIST
##########################################################################
[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['./build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb'], model_type='tensorflow', named_inputs_shape=None, out_filename='/tmp/miniResNet_org.xmodel', proto=None)
[INFO] tensorflow model: /workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/build/quantized_results/fmnist/miniResNet/quantize_eval_model.pb
[INFO] parse raw model     :  0%|          | 0/458 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|| 458/458 [00:00<00:00, 25306.17it/s]
[INFO] infer shape (NHWC)  :  0%|          | 0/519 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|| 519/519 [00:00<00:00, 11721.80it/s]
[INFO] perform level-0 opt :  0%|          | 0/2 [00:00<?, ?it/s]                            [INFO] perform level-0 opt :100%|| 2/2 [00:00<00:00, 68.03it/s]
[INFO] perform level-1 opt :  0%|          | 0/6 [00:00<?, ?it/s]                            [INFO] perform level-1 opt :100%|| 6/6 [00:00<00:00, 67.51it/s]
[INFO] generate xmodel     :  0%|          | 0/516 [00:00<?, ?it/s]                          [INFO] generate xmodel     :100%|| 516/516 [00:00<00:00, 13696.38it/s]
[INFO] dump xmodel ...[INFO] dump xmodel: /tmp/miniResNet_org.xmodel
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Compile mode: dpu
[UNILOG][INFO] Debug mode: function
[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B4096_MAX_BG2
[UNILOG][INFO] Graph name: quantize_eval_model, with op num: 798
[UNILOG][INFO] Begin to compile...
[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1
[UNILOG][INFO] Compile done.
[UNILOG][INFO] The meta json is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/meta.json"
[UNILOG][INFO] The compiled xmodel is saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/miniResNet.xmodel"
[UNILOG][INFO] The compiled xmodel's md5sum is 759a0921916571638de1b5c1c5a6ba23, and has been saved to "/workspace/Vitis-AI-1v4/tutorials/VAI-Keras-GoogleNet-ResNet/files/./build/compile/fmnist/miniResNet/md5sum.txt"
**************************************************
* VITIS_AI Compilation - Xilinx Inc.
**************************************************

##########################################################################
COMPILATION COMPLETED  on FMNIST on ZCU104
##########################################################################
